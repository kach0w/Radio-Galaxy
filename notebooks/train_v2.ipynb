{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\kar\\anaconda3\\envs\\asdfs\\lib\\site-packages (2.2.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: torchvision in c:\\users\\kar\\anaconda3\\envs\\asdfs\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: torchsummary in c:\\users\\kar\\anaconda3\\envs\\asdfs\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\kar\\anaconda3\\envs\\asdfs\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\kar\\anaconda3\\envs\\asdfs\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\kar\\anaconda3\\envs\\asdfs\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\kar\\anaconda3\\envs\\asdfs\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kar\\anaconda3\\envs\\asdfs\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\kar\\anaconda3\\envs\\asdfs\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\kar\\anaconda3\\envs\\asdfs\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\kar\\anaconda3\\envs\\asdfs\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kar\\anaconda3\\envs\\asdfs\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\kar\\anaconda3\\envs\\asdfs\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping C:\\Users\\kar\\anaconda3\\envs\\asdfs\\Lib\\site-packages\\python_dateutil-2.8.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\kar\\anaconda3\\envs\\asdfs\\Lib\\site-packages\\python_dateutil-2.8.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\kar\\anaconda3\\envs\\asdfs\\Lib\\site-packages\\python_dateutil-2.8.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\kar\\anaconda3\\envs\\asdfs\\Lib\\site-packages\\python_dateutil-2.8.2.dist-info due to invalid metadata entry 'name'\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchsummary\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "import json\n",
    "import os\n",
    "from MiraBest_Goof import MiraBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize([0.5],[0.5]),\n",
    "     transforms.RandomHorizontalFlip(0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = MiraBest(root='../batches', train=True, download=True, transform=transform)  \n",
    "batch_size_train = 2\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size_train, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = MiraBest(root='../batches', train=False, download=True, transform=transform) \n",
    "batch_size_test = 2\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size_test, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {\"train\": 693, \"test\": 77}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 3, 3)\n",
    "        self.conv2 = nn.Conv2d(3, 3, 3)\n",
    "        self.conv3 = nn.Conv2d(3, 6, 3)\n",
    "        # self.fc1 = nn.Linear(16 * 73 * 73, 120) \n",
    "        # self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(6*17*17, 2) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
    "        x = x.view(-1, 6*17*17)\n",
    "        # x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 3, 148, 148]              30\n",
      "            Conv2d-2            [-1, 3, 72, 72]              84\n",
      "            Conv2d-3            [-1, 6, 34, 34]             168\n",
      "            Linear-4                    [-1, 2]           3,470\n",
      "================================================================\n",
      "Total params: 3,752\n",
      "Trainable params: 3,752\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.09\n",
      "Forward/backward pass size (MB): 0.67\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.77\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "summary(net,(1,150,150))\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adagrad(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_epoch = []\n",
    "fig = plt.figure()\n",
    "ax0 = fig.add_subplot(121, title=\"loss\")\n",
    "ax1 = fig.add_subplot(122, title=\"acc\")\n",
    "\n",
    "y_loss = {}\n",
    "y_loss[\"train\"] = []\n",
    "y_loss[\"test\"] = []\n",
    "y_acc = {}\n",
    "y_acc[\"train\"] = []\n",
    "y_acc[\"test\"] = []\n",
    "#https://sybernix.medium.com/drawing-loss-curves-for-deep-neural-network-training-in-pytorch-ac617b24c388\n",
    "\n",
    "def draw_curve(directory):\n",
    "    ax0.plot(x_epoch, y_loss['train'], 'bo-', label='train')\n",
    "    ax0.plot(x_epoch, y_loss['test'], 'ro-', label='test')\n",
    "    ax1.plot(x_epoch, y_acc['train'], 'bo-', label='train')\n",
    "    ax1.plot(x_epoch, y_acc['test'], 'ro-', label='test')\n",
    "    file_name = \"train_\" + str(len(x_epoch)) + \".jpg\"\n",
    "    fig.savefig(os.path.join(directory, file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pywt\n",
    "for i, data in enumerate(trainset, 0):\n",
    "    images, labels = data\n",
    "    for image in images:\n",
    "        coeffs2 = pywt.dwt2(image, 'bior1.3')\n",
    "        LL, (LH, HL, HH) = coeffs2\n",
    "\n",
    "        fig = plt.figure(figsize=(15, 5))\n",
    "        ax1 = fig.add_subplot(1,5,1)\n",
    "        ax2 = fig.add_subplot(1,5,2)\n",
    "        ax3 = fig.add_subplot(1,5,3)\n",
    "        ax4 = fig.add_subplot(1,5,4)\n",
    "        ax5 = fig.add_subplot(1,5,5)\n",
    "        \n",
    "        ax1.imshow(image)\n",
    "        ax1.set_title(\"Original\")\n",
    "        ax2.imshow(LL, interpolation=\"nearest\") \n",
    "        ax2.set_title(\"Approximation\")\n",
    "        ax3.imshow(LH, interpolation=\"nearest\") \n",
    "        ax3.set_title(\"Horizontal detail\")\n",
    "        ax4.imshow(HL, interpolation=\"nearest\") \n",
    "        ax4.set_title(\"Vertical detail\")\n",
    "        ax5.imshow(HH, interpolation=\"nearest\") \n",
    "        ax5.set_title(\"Diagonal detail\")\n",
    "        plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximation\n",
      "----------\n",
      "Epoch 1/40\n",
      "TRAIN:\n",
      "loss: 0.6930 | accuracy: 0.5253\n",
      "TEST:\n",
      "loss: 0.6942 | accuracy: 0.5584\n",
      "----------\n",
      "Epoch 2/40\n",
      "TRAIN:\n",
      "loss: 0.6760 | accuracy: 0.5786\n",
      "TEST:\n",
      "loss: 0.6453 | accuracy: 0.6883\n",
      "----------\n",
      "Epoch 3/40\n",
      "TRAIN:\n",
      "loss: 0.6539 | accuracy: 0.6537\n",
      "TEST:\n",
      "loss: 0.6152 | accuracy: 0.7273\n",
      "----------\n",
      "Epoch 4/40\n",
      "TRAIN:\n",
      "loss: 0.6303 | accuracy: 0.6696\n",
      "TEST:\n",
      "loss: 0.5749 | accuracy: 0.7403\n",
      "----------\n",
      "Epoch 5/40\n",
      "TRAIN:\n",
      "loss: 0.6118 | accuracy: 0.6739\n",
      "TEST:\n",
      "loss: 0.5545 | accuracy: 0.7403\n",
      "----------\n",
      "Epoch 6/40\n",
      "TRAIN:\n",
      "loss: 0.5943 | accuracy: 0.6681\n",
      "TEST:\n",
      "loss: 0.5613 | accuracy: 0.7143\n",
      "----------\n",
      "Epoch 7/40\n",
      "TRAIN:\n",
      "loss: 0.5739 | accuracy: 0.6941\n",
      "TEST:\n",
      "loss: 0.5596 | accuracy: 0.6494\n",
      "----------\n",
      "Epoch 8/40\n",
      "TRAIN:\n",
      "loss: 0.5680 | accuracy: 0.6869\n",
      "TEST:\n",
      "loss: 0.5752 | accuracy: 0.6753\n",
      "----------\n",
      "Epoch 9/40\n",
      "TRAIN:\n",
      "loss: 0.5604 | accuracy: 0.7100\n",
      "TEST:\n",
      "loss: 0.5577 | accuracy: 0.6883\n",
      "----------\n",
      "Epoch 10/40\n",
      "TRAIN:\n",
      "loss: 0.5418 | accuracy: 0.7316\n",
      "TEST:\n",
      "loss: 0.5687 | accuracy: 0.6623\n",
      "----------\n",
      "Epoch 11/40\n",
      "TRAIN:\n",
      "loss: 0.5326 | accuracy: 0.7330\n",
      "TEST:\n",
      "loss: 0.5421 | accuracy: 0.6753\n",
      "----------\n",
      "Epoch 12/40\n",
      "TRAIN:\n",
      "loss: 0.5303 | accuracy: 0.7403\n",
      "TEST:\n",
      "loss: 0.5402 | accuracy: 0.6883\n",
      "----------\n",
      "Epoch 13/40\n",
      "TRAIN:\n",
      "loss: 0.5238 | accuracy: 0.7345\n",
      "TEST:\n",
      "loss: 0.5466 | accuracy: 0.6494\n",
      "----------\n",
      "Epoch 14/40\n",
      "TRAIN:\n",
      "loss: 0.5314 | accuracy: 0.7345\n",
      "TEST:\n",
      "loss: 0.5595 | accuracy: 0.6883\n",
      "----------\n",
      "Epoch 15/40\n",
      "TRAIN:\n",
      "loss: 0.5208 | accuracy: 0.7302\n",
      "TEST:\n",
      "loss: 0.5318 | accuracy: 0.6494\n",
      "----------\n",
      "Epoch 16/40\n",
      "TRAIN:\n",
      "loss: 0.5165 | accuracy: 0.7302\n",
      "TEST:\n",
      "loss: 0.5596 | accuracy: 0.6883\n",
      "----------\n",
      "Epoch 17/40\n",
      "TRAIN:\n",
      "loss: 0.5086 | accuracy: 0.7475\n",
      "TEST:\n",
      "loss: 0.5346 | accuracy: 0.6753\n",
      "----------\n",
      "Epoch 18/40\n",
      "TRAIN:\n",
      "loss: 0.5085 | accuracy: 0.7532\n",
      "TEST:\n",
      "loss: 0.5612 | accuracy: 0.6753\n",
      "----------\n",
      "Epoch 19/40\n",
      "TRAIN:\n",
      "loss: 0.5015 | accuracy: 0.7532\n",
      "TEST:\n",
      "loss: 0.5493 | accuracy: 0.6364\n",
      "----------\n",
      "Epoch 20/40\n",
      "TRAIN:\n",
      "loss: 0.5045 | accuracy: 0.7489\n",
      "TEST:\n",
      "loss: 0.5606 | accuracy: 0.6753\n",
      "----------\n",
      "Epoch 21/40\n",
      "TRAIN:\n",
      "loss: 0.4986 | accuracy: 0.7547\n",
      "TEST:\n",
      "loss: 0.5522 | accuracy: 0.7013\n",
      "----------\n",
      "Epoch 22/40\n",
      "TRAIN:\n",
      "loss: 0.4995 | accuracy: 0.7590\n",
      "TEST:\n",
      "loss: 0.5506 | accuracy: 0.7013\n",
      "----------\n",
      "Epoch 23/40\n",
      "TRAIN:\n",
      "loss: 0.4958 | accuracy: 0.7547\n",
      "TEST:\n",
      "loss: 0.5423 | accuracy: 0.6753\n",
      "----------\n",
      "Epoch 24/40\n",
      "TRAIN:\n",
      "loss: 0.4917 | accuracy: 0.7605\n",
      "TEST:\n",
      "loss: 0.5644 | accuracy: 0.6623\n",
      "----------\n",
      "Epoch 25/40\n",
      "TRAIN:\n",
      "loss: 0.4903 | accuracy: 0.7734\n",
      "TEST:\n",
      "loss: 0.5461 | accuracy: 0.6623\n",
      "----------\n",
      "Epoch 26/40\n",
      "TRAIN:\n",
      "loss: 0.4889 | accuracy: 0.7532\n",
      "TEST:\n",
      "loss: 0.5205 | accuracy: 0.6883\n",
      "----------\n",
      "Epoch 27/40\n",
      "TRAIN:\n",
      "loss: 0.4899 | accuracy: 0.7648\n",
      "TEST:\n",
      "loss: 0.5455 | accuracy: 0.6753\n",
      "----------\n",
      "Epoch 28/40\n",
      "TRAIN:\n",
      "loss: 0.4840 | accuracy: 0.7648\n",
      "TEST:\n",
      "loss: 0.5476 | accuracy: 0.7013\n",
      "----------\n",
      "Epoch 29/40\n",
      "TRAIN:\n",
      "loss: 0.4836 | accuracy: 0.7706\n",
      "TEST:\n",
      "loss: 0.5648 | accuracy: 0.6883\n",
      "----------\n",
      "Epoch 30/40\n",
      "TRAIN:\n",
      "loss: 0.4814 | accuracy: 0.7691\n",
      "TEST:\n",
      "loss: 0.5577 | accuracy: 0.6623\n",
      "----------\n",
      "Epoch 31/40\n",
      "TRAIN:\n",
      "loss: 0.4791 | accuracy: 0.7706\n",
      "TEST:\n",
      "loss: 0.5584 | accuracy: 0.6753\n",
      "----------\n",
      "Epoch 32/40\n",
      "TRAIN:\n",
      "loss: 0.4757 | accuracy: 0.7677\n",
      "TEST:\n",
      "loss: 0.5637 | accuracy: 0.6623\n",
      "----------\n",
      "Epoch 33/40\n",
      "TRAIN:\n",
      "loss: 0.4778 | accuracy: 0.7706\n",
      "TEST:\n",
      "loss: 0.5582 | accuracy: 0.6883\n",
      "----------\n",
      "Epoch 34/40\n",
      "TRAIN:\n",
      "loss: 0.4731 | accuracy: 0.7807\n",
      "TEST:\n",
      "loss: 0.5393 | accuracy: 0.6883\n",
      "----------\n",
      "Epoch 35/40\n",
      "TRAIN:\n",
      "loss: 0.4722 | accuracy: 0.7864\n",
      "TEST:\n",
      "loss: 0.5580 | accuracy: 0.7273\n",
      "----------\n",
      "Epoch 36/40\n",
      "TRAIN:\n",
      "loss: 0.4673 | accuracy: 0.7864\n",
      "TEST:\n",
      "loss: 0.5471 | accuracy: 0.6753\n",
      "----------\n",
      "Epoch 37/40\n",
      "TRAIN:\n",
      "loss: 0.4680 | accuracy: 0.7879\n",
      "TEST:\n",
      "loss: 0.5301 | accuracy: 0.7143\n",
      "----------\n",
      "Epoch 38/40\n",
      "TRAIN:\n",
      "loss: 0.4670 | accuracy: 0.7835\n",
      "TEST:\n",
      "loss: 0.5715 | accuracy: 0.6364\n",
      "----------\n",
      "Epoch 39/40\n",
      "TRAIN:\n",
      "loss: 0.4599 | accuracy: 0.7749\n",
      "TEST:\n",
      "loss: 0.5941 | accuracy: 0.6623\n",
      "----------\n",
      "Epoch 40/40\n",
      "TRAIN:\n",
      "loss: 0.4654 | accuracy: 0.7720\n",
      "TEST:\n",
      "loss: 0.5588 | accuracy: 0.6753\n"
     ]
    }
   ],
   "source": [
    "#approximation\n",
    "print(\"Approximation\")\n",
    "x_epoch = []\n",
    "num_epochs = 40\n",
    "for epoch in range(num_epochs):\n",
    "    print('-' * 10)\n",
    "    print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "    for phase in [\"train\", \"test\"]:     \n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0.0 \n",
    "        if(phase == \"train\"):\n",
    "            net.train(True)\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                images, labels = data\n",
    "                for image in images:\n",
    "                    coeffs2 = pywt.dwt2(image, 'db1')\n",
    "                    LL, (LH, HL, HH) = coeffs2\n",
    "                    image = LL # approximation\n",
    "                now_batch_size, c, h, w = images.shape\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(images)\n",
    "                _, predictions = torch.max(outputs.data, 1)\n",
    "                l = loss(outputs, labels)\n",
    "                l.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += l.item() * now_batch_size\n",
    "                del l\n",
    "                running_corrects += float(torch.sum(predictions == labels.data))\n",
    "        else:\n",
    "            net.train(False)\n",
    "            for i, data in enumerate(testloader, 0):\n",
    "                images, labels = data\n",
    "                for image in images:\n",
    "                    coeffs2 = pywt.dwt2(image, 'db1')\n",
    "                    LL, (LH, HL, HH) = coeffs2\n",
    "                    image = LL # approximation\n",
    "                now_batch_size, c, h, w = images.shape\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(images)\n",
    "                _, predictions = torch.max(outputs.data, 1)\n",
    "                l = loss(outputs, labels)\n",
    "\n",
    "                running_loss += l.item() * now_batch_size\n",
    "                del l\n",
    "                running_corrects += float(torch.sum(predictions == labels.data))\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "        print('{}:\\nloss: {:.4f} | accuracy: {:.4f}'.format(phase.upper(), epoch_loss, epoch_acc))\n",
    "        if(epoch % 5 == 1):\n",
    "            y_loss[phase].append(epoch_loss)\n",
    "            y_acc[phase].append(epoch_acc)\n",
    "        if(phase == \"test\" and epoch % 5 == 1):\n",
    "            x_epoch.append(epoch)\n",
    "            draw_curve('../lossGraphs_v2_approximation')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Horizontal\n",
      "----------\n",
      "Epoch 1/40\n",
      "TRAIN:\n",
      "loss: 0.7065 | accuracy: 0.5368\n",
      "TEST:\n",
      "loss: 0.6868 | accuracy: 0.5584\n",
      "----------\n",
      "Epoch 2/40\n",
      "TRAIN:\n",
      "loss: 0.6913 | accuracy: 0.5426\n",
      "TEST:\n",
      "loss: 0.6961 | accuracy: 0.5584\n",
      "----------\n",
      "Epoch 3/40\n",
      "TRAIN:\n",
      "loss: 0.6820 | accuracy: 0.5772\n",
      "TEST:\n",
      "loss: 0.6575 | accuracy: 0.5584\n",
      "----------\n",
      "Epoch 4/40\n",
      "TRAIN:\n",
      "loss: 0.6621 | accuracy: 0.6176\n",
      "TEST:\n",
      "loss: 0.6386 | accuracy: 0.5974\n",
      "----------\n",
      "Epoch 5/40\n",
      "TRAIN:\n",
      "loss: 0.6491 | accuracy: 0.6190\n",
      "TEST:\n",
      "loss: 0.6137 | accuracy: 0.7143\n",
      "----------\n",
      "Epoch 6/40\n",
      "TRAIN:\n",
      "loss: 0.6317 | accuracy: 0.6739\n",
      "TEST:\n",
      "loss: 0.6047 | accuracy: 0.7013\n",
      "----------\n",
      "Epoch 7/40\n",
      "TRAIN:\n",
      "loss: 0.6123 | accuracy: 0.6912\n",
      "TEST:\n",
      "loss: 0.5811 | accuracy: 0.7143\n",
      "----------\n",
      "Epoch 8/40\n",
      "TRAIN:\n",
      "loss: 0.6052 | accuracy: 0.6811\n",
      "TEST:\n",
      "loss: 0.5749 | accuracy: 0.7143\n",
      "----------\n",
      "Epoch 9/40\n",
      "TRAIN:\n",
      "loss: 0.5927 | accuracy: 0.7042\n",
      "TEST:\n",
      "loss: 0.5639 | accuracy: 0.7532\n",
      "----------\n",
      "Epoch 10/40\n",
      "TRAIN:\n",
      "loss: 0.5854 | accuracy: 0.7143\n",
      "TEST:\n",
      "loss: 0.5702 | accuracy: 0.7143\n",
      "----------\n",
      "Epoch 11/40\n",
      "TRAIN:\n",
      "loss: 0.5738 | accuracy: 0.7316\n",
      "TEST:\n",
      "loss: 0.5421 | accuracy: 0.7532\n",
      "----------\n",
      "Epoch 12/40\n",
      "TRAIN:\n",
      "loss: 0.5610 | accuracy: 0.7330\n",
      "TEST:\n",
      "loss: 0.5786 | accuracy: 0.7143\n",
      "----------\n",
      "Epoch 13/40\n",
      "TRAIN:\n",
      "loss: 0.5616 | accuracy: 0.7374\n",
      "TEST:\n",
      "loss: 0.5453 | accuracy: 0.7792\n",
      "----------\n",
      "Epoch 14/40\n",
      "TRAIN:\n",
      "loss: 0.5532 | accuracy: 0.7460\n",
      "TEST:\n",
      "loss: 0.5480 | accuracy: 0.7143\n",
      "----------\n",
      "Epoch 15/40\n",
      "TRAIN:\n",
      "loss: 0.5524 | accuracy: 0.7330\n",
      "TEST:\n",
      "loss: 0.5677 | accuracy: 0.7403\n",
      "----------\n",
      "Epoch 16/40\n",
      "TRAIN:\n",
      "loss: 0.5409 | accuracy: 0.7446\n",
      "TEST:\n",
      "loss: 0.5439 | accuracy: 0.7143\n",
      "----------\n",
      "Epoch 17/40\n",
      "TRAIN:\n",
      "loss: 0.5347 | accuracy: 0.7475\n",
      "TEST:\n",
      "loss: 0.5454 | accuracy: 0.7532\n",
      "----------\n",
      "Epoch 18/40\n",
      "TRAIN:\n",
      "loss: 0.5348 | accuracy: 0.7518\n",
      "TEST:\n",
      "loss: 0.5430 | accuracy: 0.7273\n",
      "----------\n",
      "Epoch 19/40\n",
      "TRAIN:\n",
      "loss: 0.5259 | accuracy: 0.7547\n",
      "TEST:\n",
      "loss: 0.5402 | accuracy: 0.7532\n",
      "----------\n",
      "Epoch 20/40\n",
      "TRAIN:\n",
      "loss: 0.5238 | accuracy: 0.7576\n",
      "TEST:\n",
      "loss: 0.5385 | accuracy: 0.6753\n",
      "----------\n",
      "Epoch 21/40\n",
      "TRAIN:\n",
      "loss: 0.5221 | accuracy: 0.7547\n",
      "TEST:\n",
      "loss: 0.5385 | accuracy: 0.6883\n",
      "----------\n",
      "Epoch 22/40\n",
      "TRAIN:\n",
      "loss: 0.5214 | accuracy: 0.7590\n",
      "TEST:\n",
      "loss: 0.5246 | accuracy: 0.7403\n",
      "----------\n",
      "Epoch 23/40\n",
      "TRAIN:\n",
      "loss: 0.5129 | accuracy: 0.7576\n",
      "TEST:\n",
      "loss: 0.5490 | accuracy: 0.7662\n",
      "----------\n",
      "Epoch 24/40\n",
      "TRAIN:\n",
      "loss: 0.5119 | accuracy: 0.7590\n",
      "TEST:\n",
      "loss: 0.5657 | accuracy: 0.7403\n",
      "----------\n",
      "Epoch 25/40\n",
      "TRAIN:\n",
      "loss: 0.4971 | accuracy: 0.7749\n",
      "TEST:\n",
      "loss: 0.5306 | accuracy: 0.7532\n",
      "----------\n",
      "Epoch 26/40\n",
      "TRAIN:\n",
      "loss: 0.4977 | accuracy: 0.7965\n",
      "TEST:\n",
      "loss: 0.5237 | accuracy: 0.7013\n",
      "----------\n",
      "Epoch 27/40\n",
      "TRAIN:\n",
      "loss: 0.4909 | accuracy: 0.7807\n",
      "TEST:\n",
      "loss: 0.5383 | accuracy: 0.7532\n",
      "----------\n",
      "Epoch 28/40\n",
      "TRAIN:\n",
      "loss: 0.4877 | accuracy: 0.7908\n",
      "TEST:\n",
      "loss: 0.5523 | accuracy: 0.7143\n",
      "----------\n",
      "Epoch 29/40\n",
      "TRAIN:\n",
      "loss: 0.4903 | accuracy: 0.7864\n",
      "TEST:\n",
      "loss: 0.5170 | accuracy: 0.7532\n",
      "----------\n",
      "Epoch 30/40\n",
      "TRAIN:\n",
      "loss: 0.4856 | accuracy: 0.7778\n",
      "TEST:\n",
      "loss: 0.5398 | accuracy: 0.7013\n",
      "----------\n",
      "Epoch 31/40\n",
      "TRAIN:\n",
      "loss: 0.4891 | accuracy: 0.7807\n",
      "TEST:\n",
      "loss: 0.5365 | accuracy: 0.7403\n",
      "----------\n",
      "Epoch 32/40\n",
      "TRAIN:\n",
      "loss: 0.4822 | accuracy: 0.7734\n",
      "TEST:\n",
      "loss: 0.5524 | accuracy: 0.7662\n",
      "----------\n",
      "Epoch 33/40\n",
      "TRAIN:\n",
      "loss: 0.4819 | accuracy: 0.7807\n",
      "TEST:\n",
      "loss: 0.5254 | accuracy: 0.7403\n",
      "----------\n",
      "Epoch 34/40\n",
      "TRAIN:\n",
      "loss: 0.4800 | accuracy: 0.7850\n",
      "TEST:\n",
      "loss: 0.5380 | accuracy: 0.7403\n",
      "----------\n",
      "Epoch 35/40\n",
      "TRAIN:\n",
      "loss: 0.4675 | accuracy: 0.7937\n",
      "TEST:\n",
      "loss: 0.5554 | accuracy: 0.7143\n",
      "----------\n",
      "Epoch 36/40\n",
      "TRAIN:\n",
      "loss: 0.4706 | accuracy: 0.7864\n",
      "TEST:\n",
      "loss: 0.5584 | accuracy: 0.7273\n",
      "----------\n",
      "Epoch 37/40\n",
      "TRAIN:\n",
      "loss: 0.4665 | accuracy: 0.7792\n",
      "TEST:\n",
      "loss: 0.5306 | accuracy: 0.7403\n",
      "----------\n",
      "Epoch 38/40\n",
      "TRAIN:\n",
      "loss: 0.4714 | accuracy: 0.7763\n",
      "TEST:\n",
      "loss: 0.5194 | accuracy: 0.7532\n",
      "----------\n",
      "Epoch 39/40\n",
      "TRAIN:\n",
      "loss: 0.4653 | accuracy: 0.7821\n",
      "TEST:\n",
      "loss: 0.5655 | accuracy: 0.7143\n",
      "----------\n",
      "Epoch 40/40\n",
      "TRAIN:\n",
      "loss: 0.4506 | accuracy: 0.7908\n",
      "TEST:\n",
      "loss: 0.5255 | accuracy: 0.7143\n"
     ]
    }
   ],
   "source": [
    "#horizontal\n",
    "print(\"Horizontal\")\n",
    "x_epoch = []\n",
    "num_epochs = 40\n",
    "for epoch in range(num_epochs):\n",
    "    print('-' * 10)\n",
    "    print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "    for phase in [\"train\", \"test\"]:     \n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0.0 \n",
    "        if(phase == \"train\"):\n",
    "            net.train(True)\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                images, labels = data\n",
    "                for image in images:\n",
    "                    coeffs2 = pywt.dwt2(image, 'db1')\n",
    "                    LL, (LH, HL, HH) = coeffs2\n",
    "                    image = LH # approximation\n",
    "                now_batch_size, c, h, w = images.shape\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(images)\n",
    "                _, predictions = torch.max(outputs.data, 1)\n",
    "                l = loss(outputs, labels)\n",
    "                l.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += l.item() * now_batch_size\n",
    "                del l\n",
    "                running_corrects += float(torch.sum(predictions == labels.data))\n",
    "        else:\n",
    "            net.train(False)\n",
    "            for i, data in enumerate(testloader, 0):\n",
    "                images, labels = data\n",
    "                for image in images:\n",
    "                    coeffs2 = pywt.dwt2(image, 'db1')\n",
    "                    LL, (LH, HL, HH) = coeffs2\n",
    "                    image = LH # approximation\n",
    "                now_batch_size, c, h, w = images.shape\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(images)\n",
    "                _, predictions = torch.max(outputs.data, 1)\n",
    "                l = loss(outputs, labels)\n",
    "\n",
    "                running_loss += l.item() * now_batch_size\n",
    "                del l\n",
    "                running_corrects += float(torch.sum(predictions == labels.data))\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "        print('{}:\\nloss: {:.4f} | accuracy: {:.4f}'.format(phase.upper(), epoch_loss, epoch_acc))\n",
    "        if(epoch % 5 == 1):\n",
    "            y_loss[phase].append(epoch_loss)\n",
    "            y_acc[phase].append(epoch_acc)\n",
    "        if(phase == \"test\" and epoch % 5 == 1):\n",
    "            x_epoch.append(epoch)\n",
    "            draw_curve('../lossGraphs_v3_horizontal')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertical\n",
      "----------\n",
      "Epoch 1/40\n",
      "TRAIN:\n",
      "loss: 0.7016 | accuracy: 0.5310\n",
      "TEST:\n",
      "loss: 0.6870 | accuracy: 0.5584\n",
      "----------\n",
      "Epoch 2/40\n",
      "TRAIN:\n",
      "loss: 0.6895 | accuracy: 0.5570\n",
      "TEST:\n",
      "loss: 0.6884 | accuracy: 0.5584\n",
      "----------\n",
      "Epoch 3/40\n",
      "TRAIN:\n",
      "loss: 0.6888 | accuracy: 0.5599\n",
      "TEST:\n",
      "loss: 0.6880 | accuracy: 0.5584\n",
      "----------\n",
      "Epoch 4/40\n",
      "TRAIN:\n",
      "loss: 0.6881 | accuracy: 0.5599\n",
      "TEST:\n",
      "loss: 0.6867 | accuracy: 0.5584\n",
      "----------\n",
      "Epoch 5/40\n",
      "TRAIN:\n",
      "loss: 0.6865 | accuracy: 0.5628\n",
      "TEST:\n",
      "loss: 0.6869 | accuracy: 0.5584\n",
      "----------\n",
      "Epoch 6/40\n",
      "TRAIN:\n",
      "loss: 0.6869 | accuracy: 0.5599\n",
      "TEST:\n",
      "loss: 0.6868 | accuracy: 0.5584\n",
      "----------\n",
      "Epoch 7/40\n",
      "TRAIN:\n",
      "loss: 0.6848 | accuracy: 0.5599\n",
      "TEST:\n",
      "loss: 0.6849 | accuracy: 0.5584\n",
      "----------\n",
      "Epoch 8/40\n",
      "TRAIN:\n",
      "loss: 0.6838 | accuracy: 0.5599\n",
      "TEST:\n",
      "loss: 0.6838 | accuracy: 0.5584\n",
      "----------\n",
      "Epoch 9/40\n",
      "TRAIN:\n",
      "loss: 0.6824 | accuracy: 0.5599\n",
      "TEST:\n",
      "loss: 0.6826 | accuracy: 0.5584\n",
      "----------\n",
      "Epoch 10/40\n",
      "TRAIN:\n",
      "loss: 0.6821 | accuracy: 0.5584\n",
      "TEST:\n",
      "loss: 0.6815 | accuracy: 0.5584\n",
      "----------\n",
      "Epoch 11/40\n",
      "TRAIN:\n",
      "loss: 0.6796 | accuracy: 0.5613\n",
      "TEST:\n",
      "loss: 0.6803 | accuracy: 0.5584\n",
      "----------\n",
      "Epoch 12/40\n",
      "TRAIN:\n",
      "loss: 0.6783 | accuracy: 0.5613\n",
      "TEST:\n",
      "loss: 0.6803 | accuracy: 0.5584\n",
      "----------\n",
      "Epoch 13/40\n",
      "TRAIN:\n",
      "loss: 0.6775 | accuracy: 0.5599\n",
      "TEST:\n",
      "loss: 0.6767 | accuracy: 0.5584\n",
      "----------\n",
      "Epoch 14/40\n",
      "TRAIN:\n",
      "loss: 0.6748 | accuracy: 0.5671\n",
      "TEST:\n",
      "loss: 0.6784 | accuracy: 0.5584\n",
      "----------\n",
      "Epoch 15/40\n",
      "TRAIN:\n",
      "loss: 0.6737 | accuracy: 0.5657\n",
      "TEST:\n",
      "loss: 0.6750 | accuracy: 0.5584\n",
      "----------\n",
      "Epoch 16/40\n",
      "TRAIN:\n",
      "loss: 0.6690 | accuracy: 0.5671\n",
      "TEST:\n",
      "loss: 0.6666 | accuracy: 0.5714\n",
      "----------\n",
      "Epoch 17/40\n",
      "TRAIN:\n",
      "loss: 0.6655 | accuracy: 0.5786\n",
      "TEST:\n",
      "loss: 0.6691 | accuracy: 0.5325\n",
      "----------\n",
      "Epoch 18/40\n",
      "TRAIN:\n",
      "loss: 0.6586 | accuracy: 0.5902\n",
      "TEST:\n",
      "loss: 0.6683 | accuracy: 0.5325\n",
      "----------\n",
      "Epoch 19/40\n",
      "TRAIN:\n",
      "loss: 0.6542 | accuracy: 0.5743\n",
      "TEST:\n",
      "loss: 0.6659 | accuracy: 0.4805\n",
      "----------\n",
      "Epoch 20/40\n",
      "TRAIN:\n",
      "loss: 0.6531 | accuracy: 0.5988\n",
      "TEST:\n",
      "loss: 0.6606 | accuracy: 0.5584\n",
      "----------\n",
      "Epoch 21/40\n",
      "TRAIN:\n",
      "loss: 0.6467 | accuracy: 0.6320\n",
      "TEST:\n",
      "loss: 0.6535 | accuracy: 0.5065\n",
      "----------\n",
      "Epoch 22/40\n",
      "TRAIN:\n",
      "loss: 0.6396 | accuracy: 0.6364\n",
      "TEST:\n",
      "loss: 0.6565 | accuracy: 0.5714\n",
      "----------\n",
      "Epoch 23/40\n",
      "TRAIN:\n",
      "loss: 0.6353 | accuracy: 0.6537\n",
      "TEST:\n",
      "loss: 0.6391 | accuracy: 0.5714\n",
      "----------\n",
      "Epoch 24/40\n",
      "TRAIN:\n",
      "loss: 0.6269 | accuracy: 0.6508\n",
      "TEST:\n",
      "loss: 0.6402 | accuracy: 0.6234\n",
      "----------\n",
      "Epoch 25/40\n",
      "TRAIN:\n",
      "loss: 0.6202 | accuracy: 0.6811\n",
      "TEST:\n",
      "loss: 0.6561 | accuracy: 0.6883\n",
      "----------\n",
      "Epoch 26/40\n",
      "TRAIN:\n",
      "loss: 0.6090 | accuracy: 0.7100\n",
      "TEST:\n",
      "loss: 0.6182 | accuracy: 0.7403\n",
      "----------\n",
      "Epoch 27/40\n",
      "TRAIN:\n",
      "loss: 0.6039 | accuracy: 0.7114\n",
      "TEST:\n",
      "loss: 0.6127 | accuracy: 0.7273\n",
      "----------\n",
      "Epoch 28/40\n",
      "TRAIN:\n",
      "loss: 0.5927 | accuracy: 0.7359\n",
      "TEST:\n",
      "loss: 0.5834 | accuracy: 0.6883\n",
      "----------\n",
      "Epoch 29/40\n",
      "TRAIN:\n",
      "loss: 0.5830 | accuracy: 0.7446\n",
      "TEST:\n",
      "loss: 0.5862 | accuracy: 0.7403\n",
      "----------\n",
      "Epoch 30/40\n",
      "TRAIN:\n",
      "loss: 0.5748 | accuracy: 0.7475\n",
      "TEST:\n",
      "loss: 0.5815 | accuracy: 0.7403\n",
      "----------\n",
      "Epoch 31/40\n",
      "TRAIN:\n",
      "loss: 0.5608 | accuracy: 0.7504\n",
      "TEST:\n",
      "loss: 0.5467 | accuracy: 0.7143\n",
      "----------\n",
      "Epoch 32/40\n",
      "TRAIN:\n",
      "loss: 0.5599 | accuracy: 0.7403\n",
      "TEST:\n",
      "loss: 0.5433 | accuracy: 0.7662\n",
      "----------\n",
      "Epoch 33/40\n",
      "TRAIN:\n",
      "loss: 0.5512 | accuracy: 0.7359\n",
      "TEST:\n",
      "loss: 0.5635 | accuracy: 0.7532\n",
      "----------\n",
      "Epoch 34/40\n",
      "TRAIN:\n",
      "loss: 0.5445 | accuracy: 0.7590\n",
      "TEST:\n",
      "loss: 0.5480 | accuracy: 0.7532\n",
      "----------\n",
      "Epoch 35/40\n",
      "TRAIN:\n",
      "loss: 0.5334 | accuracy: 0.7518\n",
      "TEST:\n",
      "loss: 0.5425 | accuracy: 0.7922\n",
      "----------\n",
      "Epoch 36/40\n",
      "TRAIN:\n",
      "loss: 0.5249 | accuracy: 0.7633\n",
      "TEST:\n",
      "loss: 0.5263 | accuracy: 0.7662\n",
      "----------\n",
      "Epoch 37/40\n",
      "TRAIN:\n",
      "loss: 0.5167 | accuracy: 0.7778\n",
      "TEST:\n",
      "loss: 0.5487 | accuracy: 0.7013\n",
      "----------\n",
      "Epoch 38/40\n",
      "TRAIN:\n",
      "loss: 0.5153 | accuracy: 0.7749\n",
      "TEST:\n",
      "loss: 0.5054 | accuracy: 0.8182\n",
      "----------\n",
      "Epoch 39/40\n",
      "TRAIN:\n",
      "loss: 0.5075 | accuracy: 0.7648\n",
      "TEST:\n",
      "loss: 0.5203 | accuracy: 0.7532\n",
      "----------\n",
      "Epoch 40/40\n",
      "TRAIN:\n",
      "loss: 0.5005 | accuracy: 0.7778\n",
      "TEST:\n",
      "loss: 0.5091 | accuracy: 0.7273\n"
     ]
    }
   ],
   "source": [
    "#vertical\n",
    "print(\"Vertical\")\n",
    "x_epoch = []\n",
    "num_epochs = 40\n",
    "for epoch in range(num_epochs):\n",
    "    print('-' * 10)\n",
    "    print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "    for phase in [\"train\", \"test\"]:     \n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0.0 \n",
    "        if(phase == \"train\"):\n",
    "            net.train(True)\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                images, labels = data\n",
    "                for image in images:\n",
    "                    coeffs2 = pywt.dwt2(image, 'db1')\n",
    "                    LL, (LH, HL, HH) = coeffs2\n",
    "                    image = HL # approximation\n",
    "                now_batch_size, c, h, w = images.shape\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(images)\n",
    "                _, predictions = torch.max(outputs.data, 1)\n",
    "                l = loss(outputs, labels)\n",
    "                l.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += l.item() * now_batch_size\n",
    "                del l\n",
    "                running_corrects += float(torch.sum(predictions == labels.data))\n",
    "        else:\n",
    "            net.train(False)\n",
    "            for i, data in enumerate(testloader, 0):\n",
    "                images, labels = data\n",
    "                for image in images:\n",
    "                    coeffs2 = pywt.dwt2(image, 'db1')\n",
    "                    LL, (LH, HL, HH) = coeffs2\n",
    "                    image = HL # approximation\n",
    "                now_batch_size, c, h, w = images.shape\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(images)\n",
    "                _, predictions = torch.max(outputs.data, 1)\n",
    "                l = loss(outputs, labels)\n",
    "\n",
    "                running_loss += l.item() * now_batch_size\n",
    "                del l\n",
    "                running_corrects += float(torch.sum(predictions == labels.data))\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "        print('{}:\\nloss: {:.4f} | accuracy: {:.4f}'.format(phase.upper(), epoch_loss, epoch_acc))\n",
    "        if(epoch % 5 == 1):\n",
    "            y_loss[phase].append(epoch_loss)\n",
    "            y_acc[phase].append(epoch_acc)\n",
    "        if(phase == \"test\" and epoch % 5 == 1):\n",
    "            x_epoch.append(epoch)\n",
    "            draw_curve('../lossGraphs_v4_vertical')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagonal\n",
      "----------\n",
      "Epoch 1/40\n",
      "TRAIN:\n",
      "loss: 0.6945 | accuracy: 0.5584\n",
      "TEST:\n",
      "loss: 0.6877 | accuracy: 0.5584\n",
      "----------\n",
      "Epoch 2/40\n",
      "TRAIN:\n",
      "loss: 0.6869 | accuracy: 0.5570\n",
      "TEST:\n",
      "loss: 0.6818 | accuracy: 0.5584\n",
      "----------\n",
      "Epoch 3/40\n",
      "TRAIN:\n",
      "loss: 0.6810 | accuracy: 0.5844\n",
      "TEST:\n",
      "loss: 0.6771 | accuracy: 0.5844\n",
      "----------\n",
      "Epoch 4/40\n",
      "TRAIN:\n",
      "loss: 0.6697 | accuracy: 0.6205\n",
      "TEST:\n",
      "loss: 0.6604 | accuracy: 0.7143\n",
      "----------\n",
      "Epoch 5/40\n",
      "TRAIN:\n",
      "loss: 0.6566 | accuracy: 0.6782\n",
      "TEST:\n",
      "loss: 0.6250 | accuracy: 0.7792\n",
      "----------\n",
      "Epoch 6/40\n",
      "TRAIN:\n",
      "loss: 0.6343 | accuracy: 0.6869\n",
      "TEST:\n",
      "loss: 0.6050 | accuracy: 0.7532\n",
      "----------\n",
      "Epoch 7/40\n",
      "TRAIN:\n",
      "loss: 0.6149 | accuracy: 0.6926\n",
      "TEST:\n",
      "loss: 0.6063 | accuracy: 0.7143\n",
      "----------\n",
      "Epoch 8/40\n",
      "TRAIN:\n",
      "loss: 0.5992 | accuracy: 0.7027\n",
      "TEST:\n",
      "loss: 0.5977 | accuracy: 0.6753\n",
      "----------\n",
      "Epoch 9/40\n",
      "TRAIN:\n",
      "loss: 0.5848 | accuracy: 0.6883\n",
      "TEST:\n",
      "loss: 0.5795 | accuracy: 0.7403\n",
      "----------\n",
      "Epoch 10/40\n",
      "TRAIN:\n",
      "loss: 0.5581 | accuracy: 0.7345\n",
      "TEST:\n",
      "loss: 0.5662 | accuracy: 0.7143\n",
      "----------\n",
      "Epoch 11/40\n",
      "TRAIN:\n",
      "loss: 0.5539 | accuracy: 0.7374\n",
      "TEST:\n",
      "loss: 0.5497 | accuracy: 0.7273\n",
      "----------\n",
      "Epoch 12/40\n",
      "TRAIN:\n",
      "loss: 0.5438 | accuracy: 0.7532\n",
      "TEST:\n",
      "loss: 0.5571 | accuracy: 0.7532\n",
      "----------\n",
      "Epoch 13/40\n",
      "TRAIN:\n",
      "loss: 0.5431 | accuracy: 0.7460\n",
      "TEST:\n",
      "loss: 0.5583 | accuracy: 0.7143\n",
      "----------\n",
      "Epoch 14/40\n",
      "TRAIN:\n",
      "loss: 0.5356 | accuracy: 0.7273\n",
      "TEST:\n",
      "loss: 0.5683 | accuracy: 0.7013\n",
      "----------\n",
      "Epoch 15/40\n",
      "TRAIN:\n",
      "loss: 0.5183 | accuracy: 0.7475\n",
      "TEST:\n",
      "loss: 0.5470 | accuracy: 0.7013\n",
      "----------\n",
      "Epoch 16/40\n",
      "TRAIN:\n",
      "loss: 0.5202 | accuracy: 0.7446\n",
      "TEST:\n",
      "loss: 0.5596 | accuracy: 0.6753\n",
      "----------\n",
      "Epoch 17/40\n",
      "TRAIN:\n",
      "loss: 0.5138 | accuracy: 0.7662\n",
      "TEST:\n",
      "loss: 0.5727 | accuracy: 0.6883\n",
      "----------\n",
      "Epoch 18/40\n",
      "TRAIN:\n",
      "loss: 0.5191 | accuracy: 0.7576\n",
      "TEST:\n",
      "loss: 0.5686 | accuracy: 0.7013\n",
      "----------\n",
      "Epoch 19/40\n",
      "TRAIN:\n",
      "loss: 0.5181 | accuracy: 0.7374\n",
      "TEST:\n",
      "loss: 0.5441 | accuracy: 0.7273\n",
      "----------\n",
      "Epoch 20/40\n",
      "TRAIN:\n",
      "loss: 0.5032 | accuracy: 0.7605\n",
      "TEST:\n",
      "loss: 0.5377 | accuracy: 0.7143\n",
      "----------\n",
      "Epoch 21/40\n",
      "TRAIN:\n",
      "loss: 0.4953 | accuracy: 0.7605\n",
      "TEST:\n",
      "loss: 0.5706 | accuracy: 0.7143\n",
      "----------\n",
      "Epoch 22/40\n",
      "TRAIN:\n",
      "loss: 0.4935 | accuracy: 0.7662\n",
      "TEST:\n",
      "loss: 0.5294 | accuracy: 0.7403\n",
      "----------\n",
      "Epoch 23/40\n",
      "TRAIN:\n",
      "loss: 0.4911 | accuracy: 0.7691\n",
      "TEST:\n",
      "loss: 0.5763 | accuracy: 0.7273\n",
      "----------\n",
      "Epoch 24/40\n",
      "TRAIN:\n",
      "loss: 0.4929 | accuracy: 0.7720\n",
      "TEST:\n",
      "loss: 0.5429 | accuracy: 0.7273\n",
      "----------\n",
      "Epoch 25/40\n",
      "TRAIN:\n",
      "loss: 0.4912 | accuracy: 0.7547\n",
      "TEST:\n",
      "loss: 0.5488 | accuracy: 0.7273\n",
      "----------\n",
      "Epoch 26/40\n",
      "TRAIN:\n",
      "loss: 0.4893 | accuracy: 0.7720\n",
      "TEST:\n",
      "loss: 0.5421 | accuracy: 0.7143\n",
      "----------\n",
      "Epoch 27/40\n",
      "TRAIN:\n",
      "loss: 0.4798 | accuracy: 0.7893\n",
      "TEST:\n",
      "loss: 0.5404 | accuracy: 0.7403\n",
      "----------\n",
      "Epoch 28/40\n",
      "TRAIN:\n",
      "loss: 0.4622 | accuracy: 0.7937\n",
      "TEST:\n",
      "loss: 0.5380 | accuracy: 0.7143\n",
      "----------\n",
      "Epoch 29/40\n",
      "TRAIN:\n",
      "loss: 0.4818 | accuracy: 0.7706\n",
      "TEST:\n",
      "loss: 0.5606 | accuracy: 0.6883\n",
      "----------\n",
      "Epoch 30/40\n",
      "TRAIN:\n",
      "loss: 0.4621 | accuracy: 0.7893\n",
      "TEST:\n",
      "loss: 0.5235 | accuracy: 0.7403\n",
      "----------\n",
      "Epoch 31/40\n",
      "TRAIN:\n",
      "loss: 0.4800 | accuracy: 0.7734\n",
      "TEST:\n",
      "loss: 0.5432 | accuracy: 0.7013\n",
      "----------\n",
      "Epoch 32/40\n",
      "TRAIN:\n",
      "loss: 0.4529 | accuracy: 0.7937\n",
      "TEST:\n",
      "loss: 0.5635 | accuracy: 0.7143\n",
      "----------\n",
      "Epoch 33/40\n",
      "TRAIN:\n",
      "loss: 0.4588 | accuracy: 0.7850\n",
      "TEST:\n",
      "loss: 0.5819 | accuracy: 0.7143\n",
      "----------\n",
      "Epoch 34/40\n",
      "TRAIN:\n",
      "loss: 0.4488 | accuracy: 0.7922\n",
      "TEST:\n",
      "loss: 0.5251 | accuracy: 0.7013\n",
      "----------\n",
      "Epoch 35/40\n",
      "TRAIN:\n",
      "loss: 0.4465 | accuracy: 0.7994\n",
      "TEST:\n",
      "loss: 0.5578 | accuracy: 0.6623\n",
      "----------\n",
      "Epoch 36/40\n",
      "TRAIN:\n",
      "loss: 0.4490 | accuracy: 0.7994\n",
      "TEST:\n",
      "loss: 0.5139 | accuracy: 0.7403\n",
      "----------\n",
      "Epoch 37/40\n",
      "TRAIN:\n",
      "loss: 0.4478 | accuracy: 0.7951\n",
      "TEST:\n",
      "loss: 0.5409 | accuracy: 0.7273\n",
      "----------\n",
      "Epoch 38/40\n",
      "TRAIN:\n",
      "loss: 0.4360 | accuracy: 0.8167\n",
      "TEST:\n",
      "loss: 0.5692 | accuracy: 0.7143\n",
      "----------\n",
      "Epoch 39/40\n",
      "TRAIN:\n",
      "loss: 0.4252 | accuracy: 0.8110\n",
      "TEST:\n",
      "loss: 0.5426 | accuracy: 0.7273\n",
      "----------\n",
      "Epoch 40/40\n",
      "TRAIN:\n",
      "loss: 0.4397 | accuracy: 0.7951\n",
      "TEST:\n",
      "loss: 0.5224 | accuracy: 0.7273\n"
     ]
    }
   ],
   "source": [
    "#diagonal\n",
    "print(\"Diagonal\")\n",
    "x_epoch = []\n",
    "num_epochs = 40\n",
    "for epoch in range(num_epochs):\n",
    "    print('-' * 10)\n",
    "    print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "    for phase in [\"train\", \"test\"]:     \n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0.0 \n",
    "        if(phase == \"train\"):\n",
    "            net.train(True)\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                images, labels = data\n",
    "                for image in images:\n",
    "                    coeffs2 = pywt.dwt2(image, 'db1')\n",
    "                    LL, (LH, HL, HH) = coeffs2\n",
    "                    image = HH # approximation\n",
    "                now_batch_size, c, h, w = images.shape\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(images)\n",
    "                _, predictions = torch.max(outputs.data, 1)\n",
    "                l = loss(outputs, labels)\n",
    "                l.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += l.item() * now_batch_size\n",
    "                del l\n",
    "                running_corrects += float(torch.sum(predictions == labels.data))\n",
    "        else:\n",
    "            net.train(False)\n",
    "            for i, data in enumerate(testloader, 0):\n",
    "                images, labels = data\n",
    "                for image in images:\n",
    "                    coeffs2 = pywt.dwt2(image, 'db1')\n",
    "                    LL, (LH, HL, HH) = coeffs2\n",
    "                    image = HH # approximation\n",
    "                now_batch_size, c, h, w = images.shape\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(images)\n",
    "                _, predictions = torch.max(outputs.data, 1)\n",
    "                l = loss(outputs, labels)\n",
    "\n",
    "                running_loss += l.item() * now_batch_size\n",
    "                del l\n",
    "                running_corrects += float(torch.sum(predictions == labels.data))\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "        print('{}:\\nloss: {:.4f} | accuracy: {:.4f}'.format(phase.upper(), epoch_loss, epoch_acc))\n",
    "        if(epoch % 5 == 1):\n",
    "            y_loss[phase].append(epoch_loss)\n",
    "            y_acc[phase].append(epoch_acc)\n",
    "        if(phase == \"test\" and epoch % 5 == 1):\n",
    "            x_epoch.append(epoch)\n",
    "            draw_curve('../lossGraphs_v5_diagonal')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined\n",
      "----------\n",
      "Epoch 1/50\n",
      "TRAIN:\n",
      "loss: 0.6936 | accuracy: 0.5541\n",
      "TEST:\n",
      "loss: 0.6863 | accuracy: 0.5584\n",
      "----------\n",
      "Epoch 2/50\n",
      "TRAIN:\n",
      "loss: 0.6873 | accuracy: 0.5599\n",
      "TEST:\n",
      "loss: 0.6865 | accuracy: 0.5584\n",
      "----------\n",
      "Epoch 3/50\n",
      "TRAIN:\n",
      "loss: 0.6874 | accuracy: 0.5599\n",
      "TEST:\n",
      "loss: 0.6664 | accuracy: 0.5584\n",
      "----------\n",
      "Epoch 4/50\n",
      "TRAIN:\n",
      "loss: 0.6651 | accuracy: 0.6075\n",
      "TEST:\n",
      "loss: 0.6399 | accuracy: 0.6883\n",
      "----------\n",
      "Epoch 5/50\n",
      "TRAIN:\n",
      "loss: 0.6445 | accuracy: 0.6768\n",
      "TEST:\n",
      "loss: 0.6094 | accuracy: 0.7403\n",
      "----------\n",
      "Epoch 6/50\n",
      "TRAIN:\n",
      "loss: 0.6210 | accuracy: 0.6825\n",
      "TEST:\n",
      "loss: 0.5834 | accuracy: 0.7403\n",
      "----------\n",
      "Epoch 7/50\n",
      "TRAIN:\n",
      "loss: 0.5983 | accuracy: 0.6768\n",
      "TEST:\n",
      "loss: 0.5716 | accuracy: 0.7143\n",
      "----------\n",
      "Epoch 8/50\n",
      "TRAIN:\n",
      "loss: 0.5852 | accuracy: 0.7013\n",
      "TEST:\n",
      "loss: 0.5724 | accuracy: 0.7013\n",
      "----------\n",
      "Epoch 9/50\n",
      "TRAIN:\n",
      "loss: 0.5641 | accuracy: 0.7114\n",
      "TEST:\n",
      "loss: 0.5546 | accuracy: 0.7403\n",
      "----------\n",
      "Epoch 10/50\n",
      "TRAIN:\n",
      "loss: 0.5602 | accuracy: 0.7085\n",
      "TEST:\n",
      "loss: 0.5300 | accuracy: 0.7403\n",
      "----------\n",
      "Epoch 11/50\n",
      "TRAIN:\n",
      "loss: 0.5501 | accuracy: 0.7201\n",
      "TEST:\n",
      "loss: 0.5596 | accuracy: 0.6883\n",
      "----------\n",
      "Epoch 12/50\n",
      "TRAIN:\n",
      "loss: 0.5405 | accuracy: 0.7287\n",
      "TEST:\n",
      "loss: 0.5325 | accuracy: 0.7532\n",
      "----------\n",
      "Epoch 13/50\n",
      "TRAIN:\n",
      "loss: 0.5256 | accuracy: 0.7287\n",
      "TEST:\n",
      "loss: 0.5335 | accuracy: 0.7273\n",
      "----------\n",
      "Epoch 14/50\n",
      "TRAIN:\n",
      "loss: 0.5341 | accuracy: 0.7388\n",
      "TEST:\n",
      "loss: 0.5382 | accuracy: 0.7532\n",
      "----------\n",
      "Epoch 15/50\n",
      "TRAIN:\n",
      "loss: 0.5265 | accuracy: 0.7273\n",
      "TEST:\n",
      "loss: 0.5358 | accuracy: 0.7273\n",
      "----------\n",
      "Epoch 16/50\n",
      "TRAIN:\n",
      "loss: 0.5224 | accuracy: 0.7273\n",
      "TEST:\n",
      "loss: 0.5622 | accuracy: 0.6883\n",
      "----------\n",
      "Epoch 17/50\n",
      "TRAIN:\n",
      "loss: 0.5225 | accuracy: 0.7273\n",
      "TEST:\n",
      "loss: 0.5599 | accuracy: 0.6883\n",
      "----------\n",
      "Epoch 18/50\n",
      "TRAIN:\n",
      "loss: 0.5222 | accuracy: 0.7359\n",
      "TEST:\n",
      "loss: 0.5792 | accuracy: 0.7013\n",
      "----------\n",
      "Epoch 19/50\n",
      "TRAIN:\n",
      "loss: 0.5049 | accuracy: 0.7302\n",
      "TEST:\n",
      "loss: 0.5801 | accuracy: 0.6883\n",
      "----------\n",
      "Epoch 20/50\n",
      "TRAIN:\n",
      "loss: 0.4975 | accuracy: 0.7532\n",
      "TEST:\n",
      "loss: 0.5611 | accuracy: 0.6753\n",
      "----------\n",
      "Epoch 21/50\n",
      "TRAIN:\n",
      "loss: 0.4991 | accuracy: 0.7446\n",
      "TEST:\n",
      "loss: 0.5677 | accuracy: 0.6623\n",
      "----------\n",
      "Epoch 22/50\n",
      "TRAIN:\n",
      "loss: 0.5036 | accuracy: 0.7475\n",
      "TEST:\n",
      "loss: 0.5672 | accuracy: 0.6623\n",
      "----------\n",
      "Epoch 23/50\n",
      "TRAIN:\n",
      "loss: 0.5011 | accuracy: 0.7446\n",
      "TEST:\n",
      "loss: 0.5633 | accuracy: 0.6494\n",
      "----------\n",
      "Epoch 24/50\n",
      "TRAIN:\n",
      "loss: 0.4914 | accuracy: 0.7489\n",
      "TEST:\n",
      "loss: 0.5427 | accuracy: 0.7013\n",
      "----------\n",
      "Epoch 25/50\n",
      "TRAIN:\n",
      "loss: 0.4914 | accuracy: 0.7648\n",
      "TEST:\n",
      "loss: 0.5716 | accuracy: 0.6623\n",
      "----------\n",
      "Epoch 26/50\n",
      "TRAIN:\n",
      "loss: 0.4855 | accuracy: 0.7547\n",
      "TEST:\n",
      "loss: 0.5521 | accuracy: 0.6494\n",
      "----------\n",
      "Epoch 27/50\n",
      "TRAIN:\n",
      "loss: 0.4898 | accuracy: 0.7504\n",
      "TEST:\n",
      "loss: 0.5603 | accuracy: 0.6623\n",
      "----------\n",
      "Epoch 28/50\n",
      "TRAIN:\n",
      "loss: 0.4913 | accuracy: 0.7561\n",
      "TEST:\n",
      "loss: 0.5439 | accuracy: 0.6883\n",
      "----------\n",
      "Epoch 29/50\n",
      "TRAIN:\n",
      "loss: 0.4938 | accuracy: 0.7561\n",
      "TEST:\n",
      "loss: 0.5488 | accuracy: 0.6753\n",
      "----------\n",
      "Epoch 30/50\n",
      "TRAIN:\n",
      "loss: 0.4928 | accuracy: 0.7532\n",
      "TEST:\n",
      "loss: 0.5684 | accuracy: 0.6753\n",
      "----------\n",
      "Epoch 31/50\n",
      "TRAIN:\n",
      "loss: 0.4866 | accuracy: 0.7547\n",
      "TEST:\n",
      "loss: 0.5438 | accuracy: 0.6623\n",
      "----------\n",
      "Epoch 32/50\n",
      "TRAIN:\n",
      "loss: 0.4746 | accuracy: 0.7633\n",
      "TEST:\n",
      "loss: 0.5521 | accuracy: 0.7273\n",
      "----------\n",
      "Epoch 33/50\n",
      "TRAIN:\n",
      "loss: 0.4866 | accuracy: 0.7576\n",
      "TEST:\n",
      "loss: 0.5505 | accuracy: 0.6753\n",
      "----------\n",
      "Epoch 34/50\n",
      "TRAIN:\n",
      "loss: 0.4826 | accuracy: 0.7576\n",
      "TEST:\n",
      "loss: 0.5671 | accuracy: 0.6623\n",
      "----------\n",
      "Epoch 35/50\n",
      "TRAIN:\n",
      "loss: 0.4759 | accuracy: 0.7633\n",
      "TEST:\n",
      "loss: 0.5417 | accuracy: 0.7143\n",
      "----------\n",
      "Epoch 36/50\n",
      "TRAIN:\n",
      "loss: 0.4719 | accuracy: 0.7633\n",
      "TEST:\n",
      "loss: 0.5760 | accuracy: 0.6623\n",
      "----------\n",
      "Epoch 37/50\n",
      "TRAIN:\n",
      "loss: 0.4663 | accuracy: 0.7662\n",
      "TEST:\n",
      "loss: 0.5495 | accuracy: 0.6623\n",
      "----------\n",
      "Epoch 38/50\n",
      "TRAIN:\n",
      "loss: 0.4706 | accuracy: 0.7677\n",
      "TEST:\n",
      "loss: 0.5587 | accuracy: 0.6494\n",
      "----------\n",
      "Epoch 39/50\n",
      "TRAIN:\n",
      "loss: 0.4646 | accuracy: 0.7778\n",
      "TEST:\n",
      "loss: 0.5653 | accuracy: 0.6623\n",
      "----------\n",
      "Epoch 40/50\n",
      "TRAIN:\n",
      "loss: 0.4673 | accuracy: 0.7734\n",
      "TEST:\n",
      "loss: 0.5490 | accuracy: 0.7143\n",
      "----------\n",
      "Epoch 41/50\n",
      "TRAIN:\n",
      "loss: 0.4669 | accuracy: 0.7677\n",
      "TEST:\n",
      "loss: 0.5232 | accuracy: 0.6883\n",
      "----------\n",
      "Epoch 42/50\n",
      "TRAIN:\n",
      "loss: 0.4647 | accuracy: 0.7778\n",
      "TEST:\n",
      "loss: 0.5451 | accuracy: 0.6494\n",
      "----------\n",
      "Epoch 43/50\n",
      "TRAIN:\n",
      "loss: 0.4595 | accuracy: 0.7807\n",
      "TEST:\n",
      "loss: 0.5711 | accuracy: 0.6753\n",
      "----------\n",
      "Epoch 44/50\n",
      "TRAIN:\n",
      "loss: 0.4713 | accuracy: 0.7706\n",
      "TEST:\n",
      "loss: 0.5493 | accuracy: 0.6883\n",
      "----------\n",
      "Epoch 45/50\n",
      "TRAIN:\n",
      "loss: 0.4632 | accuracy: 0.7749\n",
      "TEST:\n",
      "loss: 0.5459 | accuracy: 0.7013\n",
      "----------\n",
      "Epoch 46/50\n",
      "TRAIN:\n",
      "loss: 0.4639 | accuracy: 0.7749\n",
      "TEST:\n",
      "loss: 0.5694 | accuracy: 0.6883\n",
      "----------\n",
      "Epoch 47/50\n",
      "TRAIN:\n",
      "loss: 0.4556 | accuracy: 0.7850\n",
      "TEST:\n",
      "loss: 0.5747 | accuracy: 0.7273\n",
      "----------\n",
      "Epoch 48/50\n",
      "TRAIN:\n",
      "loss: 0.4575 | accuracy: 0.7749\n",
      "TEST:\n",
      "loss: 0.5667 | accuracy: 0.7013\n",
      "----------\n",
      "Epoch 49/50\n",
      "TRAIN:\n",
      "loss: 0.4579 | accuracy: 0.7677\n",
      "TEST:\n",
      "loss: 0.5664 | accuracy: 0.7143\n",
      "----------\n",
      "Epoch 50/50\n",
      "TRAIN:\n",
      "loss: 0.4500 | accuracy: 0.7763\n",
      "TEST:\n",
      "loss: 0.5843 | accuracy: 0.6883\n"
     ]
    }
   ],
   "source": [
    "#combined\n",
    "print(\"Combined\")\n",
    "x_epoch = []\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    print('-' * 10)\n",
    "    print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "    for phase in [\"train\", \"test\"]:     \n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0.0 \n",
    "        if(phase == \"train\"):\n",
    "            net.train(True)\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                images, labels = data\n",
    "                LL_batch, LH_batch, HL_batch, HH_batch = [], [], [], []\n",
    "                for image in images:\n",
    "                    coeffs2 = pywt.dwt2(image, 'db1')\n",
    "                    LL, (LH, HL, HH) = coeffs2\n",
    "                    LL = torch.tensor(LL, dtype=torch.float32)\n",
    "                    LH = torch.tensor(LH, dtype=torch.float32)\n",
    "                    HL = torch.tensor(HL, dtype=torch.float32)\n",
    "                    HH = torch.tensor(HH, dtype=torch.float32)\n",
    "                    image =  torch.stack([LL, LH, HL, HH])\n",
    "                now_batch_size, c, h, w = images.shape\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(images)\n",
    "                _, predictions = torch.max(outputs.data, 1)\n",
    "                l = loss(outputs, labels)\n",
    "                l.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += l.item() * now_batch_size\n",
    "                del l\n",
    "                running_corrects += float(torch.sum(predictions == labels.data))\n",
    "        else:\n",
    "            net.train(False)\n",
    "            for i, data in enumerate(testloader, 0):\n",
    "                images, labels = data\n",
    "                for image in images:\n",
    "                    coeffs2 = pywt.dwt2(image, 'db1')\n",
    "                    LL, (LH, HL, HH) = coeffs2\n",
    "                    LL = torch.tensor(LL, dtype=torch.float32)\n",
    "                    LH = torch.tensor(LH, dtype=torch.float32)\n",
    "                    HL = torch.tensor(HL, dtype=torch.float32)\n",
    "                    HH = torch.tensor(HH, dtype=torch.float32)\n",
    "                    image =  torch.stack([LL, LH, HL, HH])\n",
    "                now_batch_size, c, h, w = images.shape\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(images)\n",
    "                _, predictions = torch.max(outputs.data, 1)\n",
    "                l = loss(outputs, labels)\n",
    "\n",
    "                running_loss += l.item() * now_batch_size\n",
    "                del l\n",
    "                running_corrects += float(torch.sum(predictions == labels.data))\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "        print('{}:\\nloss: {:.4f} | accuracy: {:.4f}'.format(phase.upper(), epoch_loss, epoch_acc))\n",
    "        if(epoch % 5 == 1):\n",
    "            y_loss[phase].append(epoch_loss)\n",
    "            y_acc[phase].append(epoch_acc)\n",
    "        if(phase == \"test\" and epoch % 5 == 1):\n",
    "            x_epoch.append(epoch)\n",
    "            draw_curve('../lossGraphs_v6_combined')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
